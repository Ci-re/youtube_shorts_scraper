{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['minister', 'channel_name', 'title', 'description', 'views', 'length', 'transcript', 'source'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sermons = load_dataset(\"json\", data_files=\"sermons.json\", split=\"train\")\n",
    "sermons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2998"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.mkdir(\"data_files\")\n",
    "\n",
    "dataset = sermons.filter(lambda x: len(x[\"transcript\"]) > 10)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=3): 100%|██████████| 2998/2998 [00:03<00:00, 810.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the texts\n",
    "\n",
    "import re\n",
    "\n",
    "filler_words = [\"um\", \"ah\", \"uh\",\"hm\", \"amen\"]\n",
    "pattern = r'\\b(?:' + '|'.join(filler_words) + r')\\b'\n",
    "\n",
    "def remove_escapes(example):\n",
    "    cleaned_text = [x.replace(\"\\xa0\", \" \").replace(\"\\n\", \" \") for x in example[\"transcript\"]]\n",
    "    cleaned_text = [re.sub(pattern,'', text).strip() for text in cleaned_text]\n",
    "    cleaned_text = [re.sub(r\"\\s+\", ' ', x).strip() for x in cleaned_text]\n",
    "    cleaned_text = [re.sub(r\"\\[.*?\\]\", \"\", text).strip() for text in cleaned_text]\n",
    "    example[\"transcript\"] = cleaned_text\n",
    "    return example\n",
    "\n",
    "remove_escapes = dataset.map(remove_escapes, batched=True, num_proc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.49ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.34ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 20.86ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 25.11ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 45.19ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 53.42ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 45.09ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 190.02ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 176.54ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 167.71ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 97.03ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 25.02ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 27.92ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 29.78ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.77ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 50.33ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 29.09ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 29.02ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 46.64ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 67.81ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 37.80ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 41.66ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 75.46ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 65.67ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 48.51ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 54.52ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 60.38ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 65.31ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 80.95ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 52.46ba/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(remove_escapes), 100):\n",
    "    end_index = min(i + 100, len(remove_escapes))\n",
    "    chunk = remove_escapes.select(range(i, end_index))\n",
    "    chunk.to_json(f\"data_files/data_{i}.jsonl\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_1.jsonl', 'data_2500.jsonl', 'data_2200.jsonl', 'data_1300.jsonl', 'data_900.jsonl', 'data_2600.jsonl', 'data_1100.jsonl', 'data_300.jsonl', 'data_1400.jsonl', 'data_1600.jsonl', 'data_1800.jsonl', 'data_600.jsonl', 'data_100.jsonl', 'data_1700.jsonl', 'data_1200.jsonl', 'data_2000.jsonl', 'data_2700.jsonl', 'data_200.jsonl', 'data_2800.jsonl', 'data_700.jsonl', 'data_2900.jsonl', 'data_500.jsonl', 'data_1000.jsonl', 'data_1500.jsonl', 'data_1900.jsonl', 'data_2100.jsonl', 'data_800.jsonl', 'data_2300.jsonl', 'data_2400.jsonl', 'data_0.jsonl', 'data_400.jsonl']\n",
      "data_1.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 3478.82 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [03:09<00:00,  1.90s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 37.97ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2500.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 6339.35 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [03:32<00:00,  2.12s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 40.69ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2200.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 15692.55 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [02:35<00:00,  1.55s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 67.27ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1300.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 8964.87 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [07:43<00:00,  4.63s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 34.29ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_900.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 17982.78 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [01:30<00:00,  1.11 examples/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 183.25ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2600.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 16099.74 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [02:02<00:00,  1.22s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 86.22ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1100.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 3341.62 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [10:21<00:00,  6.22s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 22.61ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_300.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 2740.23 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [12:42<00:00,  7.62s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 12.32ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1400.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 15032.81 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [04:07<00:00,  2.48s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 28.86ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1600.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 2426.77 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [15:24<00:00,  9.24s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  8.98ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1800.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 2378.22 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [15:19<00:00,  9.19s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 18.78ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_600.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 6381.30 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [06:01<00:00,  3.62s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 31.44ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_100.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 1289.33 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [16:39<00:00, 10.00s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.24ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1700.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 2551.08 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [16:41<00:00, 10.01s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.78ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1200.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 3136.89 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [11:39<00:00,  7.00s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.60ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2000.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 2686.30 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [12:09<00:00,  7.30s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 19.62ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2700.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 8608.11 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [03:04<00:00,  1.84s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 42.27ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_200.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 1264.02 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [18:06<00:00, 10.87s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.86ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2800.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 10818.43 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [04:06<00:00,  2.46s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 19.37ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_700.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 36573.98 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [00:19<00:00,  5.02 examples/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 245.51ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2900.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 98 examples [00:00, 12399.82 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 98/98 [08:13<00:00,  5.04s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 63.75ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_500.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 11434.85 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [03:19<00:00,  1.99s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 59.11ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1000.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 16234.34 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [01:36<00:00,  1.04 examples/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 114.50ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1500.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 11277.44 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [04:04<00:00,  2.45s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 32.15ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1900.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 5175.79 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [05:18<00:00,  3.18s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 33.62ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2100.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 5437.97 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [05:30<00:00,  3.30s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 32.56ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_800.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 12093.95 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [01:23<00:00,  1.20 examples/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 85.76ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2300.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 6876.92 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [03:58<00:00,  2.38s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 44.67ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2400.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 4211.95 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [05:38<00:00,  3.38s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 18.03ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_0.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 1541.67 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [15:26<00:00,  9.26s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  8.84ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_400.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100 examples [00:00, 5287.96 examples/s]\n",
      "Map (num_proc=16): 100%|██████████| 100/100 [06:02<00:00,  3.63s/ examples]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 34.07ba/s]\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spelling(example):\n",
    "    words = example[\"transcript\"].split()\n",
    "    # Remove None valuess\n",
    "    corrected_words = [\n",
    "        spell.correction(word) if spell.correction(word) and word not in spell else word \n",
    "        for word in words\n",
    "    ]\n",
    "    standard_words = \" \".join(corrected_words)\n",
    "    example[\"transcript\"] = standard_words\n",
    "    return example\n",
    "# [1,2500,2200, 1300, 900,2600,1100, 300, 1400, 1600, 1800, 600, 100, 1700, 1200]\n",
    "# os.mkdir(\"corrected_datafiles\")\n",
    "# data_files = os.listdir(\"data_files\")\n",
    "# print(data_files)\n",
    "for i in range(len(data_files)):\n",
    "    print(data_files[i])\n",
    "    data = load_dataset(\"json\", data_files=f\"data_files/{data_files[i]}\", split=\"train\")\n",
    "    testd = data.map(correct_spelling, batched=False, num_proc=16)\n",
    "    testd.to_json(f\"corrected_datafiles/data_{i}.jsonl\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
